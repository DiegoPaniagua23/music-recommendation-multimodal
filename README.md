# ğŸµ Arquitectura HÃ­brida Two-Tower para RecomendaciÃ³n Musical Multimodal

![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![DVC](https://img.shields.io/badge/DVC-Data%20Version%20Control-purple)
![Status](https://img.shields.io/badge/Status-Development-yellow)

---

## ğŸ“– DescripciÃ³n General

Este proyecto implementa un sistema de recomendaciÃ³n musical del Estado del Arte (SOTA) utilizando una arquitectura **Two-Tower** con fusiÃ³n **Cross-Modal**. El objetivo es resolver los problemas de escasez de datos (*sparsity*) y brecha semÃ¡ntica (*semantic gap*) en los sistemas tradicionales.

El modelo alinea dos espacios vectoriales:
1.  **User Tower:** Codifica la secuencia histÃ³rica de interacciones del usuario usando **SASRec** (Transformer secuencial).
2.  **Item Tower:** Codifica el contenido de la canciÃ³n mediante **AtenciÃ³n Cruzada (Cross-Attention)** entre Audio (Mel-Spectrograms), Texto (Lyrics) e Imagen (CarÃ¡tulas).

## ğŸ—ï¸ Arquitectura del Sistema


## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

Este proyecto utiliza **`uv`** para la gestiÃ³n de dependencias y **DVC** para el control de versiones de datos.

### Prerrequisitos

  * Python 3.9+
  * [uv](https://github.com/astral-sh/uv) instalado.
  * `ffmpeg` instalado en el sistema (para procesamiento de audio).

### 1\. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd proyecto-mir
```

### 2\. Instalar dependencias

```bash
uv sync
# Esto crearÃ¡ el entorno virtual e instalarÃ¡ todo lo necesario
```

### 3. Configurar Datos (DVC)

Para descargar los datos, necesitas configurar las credenciales de Google Drive. Ejecuta los siguientes comandos:

```bash
# Configurar credenciales locales (no se suben al repo, se adjuntan en el trabajo)
dvc remote modify --local proyecto_multimodal gdrive_client_id 
"<gdrive_client_id>"
dvc remote modify --local proyecto_multimodal gdrive_client_secret 
"<gdrive_client_secret>"

# Descargar datos
uv run dvc pull
```

### 4. Variables de Entorno

AsegÃºrate de tener configuradas las variables necesarias, especialmente si usas modelos de HuggingFace que requieran token (aunque mDeBERTa es pÃºblico).

```bash
export HF_HOME="./.cache/huggingface"
```

-----

## ğŸ‹ï¸â€â™‚ï¸ Entrenamiento

Para entrenar el modelo desde cero hemos utilizado el clÃºster del CIMAT (BajÃ­o), el cual cuenta con 2 GPUs en cada nodo. El funcionamiento puede variar dependiendo del hardware donde se quiera reproducir el entrenamiento (Los requerimientos de Hardware son altos, un tamaÃ±o de lote de 64 requiere mas de 24 GB VRAM). 

En todo caso, utilizamos el script `src/train.py`. Este script se encarga de:
1. Cargar y preprocesar los datos.
2. Ajustar y guardar los encoders (necesarios para inferencia).
3. Entrenar el modelo Two-Tower.

```bash
# Agregar el directorio actual al PYTHONPATH para que Python encuentre el mÃ³dulo 'src'
export PYTHONPATH=$PWD

# Para el clÃºster CIMAT utilizamos el script train.sh
uv run python -m torch.distributed.run --nproc_per_node=1 src/train.py \
    --data_path "data/spotify-kaggle/interim/lastfm_spotify_merged.csv" \
    --img_dir "data/spotify-kaggle/album_covers/" \
    --audio_dir "data/audio/mels/" \
    --lyrics_path "data/spotify-kaggle/interim/lyrics_dataset_10k_fixed.csv" \
    --epochs 10 \
    --batch_size 32

# En local (considerando una GPU).
uv run python -m torch.distributed.run --nproc_per_node=1 src/train.py \
    --data_path "data/spotify-kaggle/interim/lastfm_spotify_merged.csv" \
    --img_dir "data/spotify-kaggle/album_covers/" \
    --audio_dir "data/audio/mels/" \
    --lyrics_path "data/spotify-kaggle/interim/lyrics_dataset_10k_fixed.csv" \
    --epochs 10 \
    --batch_size 32
```

**Nota:** Los checkpoints y encoders se guardarÃ¡n automÃ¡ticamente en la carpeta `checkpoints/`.

-----

## ğŸ“Š EvaluaciÃ³n

Para evaluar el rendimiento del modelo (Recall@K, NDCG@K) sobre el conjunto de validaciÃ³n/test:

```bash
uv run python src/evaluate_metrics.py \
  --model_path "checkpoints/complete/best_model_epoch1.pth" \
  --encoders_path "checkpoints/complete/encoders.pkl" \
  --data_path "data/spotify-kaggle/interim/lastfm_spotify_merged.csv" \
  --embeddings_cache_path "checkpoints/complete/item_embeddings_cache_epoch1.pt" \
  --batch_size 32
```

-----

## ğŸ”® Inferencia y RecomendaciÃ³n

El sistema de inferencia tiene dos modos: **IndexaciÃ³n** y **RecomendaciÃ³n**.

### Paso 1: IndexaciÃ³n (`index`)
Pre-calcula los embeddings de todas las canciones del catÃ¡logo para una bÃºsqueda rÃ¡pida.

```bash
uv run python -m src.inference \
  --mode index \
  --data_path "data/spotify-kaggle/interim/lastfm_spotify_merged.csv" \
  --mapper_path "data/spotify-kaggle/interim/item_id_mapper.json" \
  --model_path "checkpoints/complete/best_model_epoch1.pth" \
  --encoders_path "checkpoints/complete/encoders.pkl" \
  --index_path "checkpoints/item_index_epoch1.pt"
```

### Paso 2: RecomendaciÃ³n (`recommend`)
Genera recomendaciones personalizadas para un usuario especÃ­fico basÃ¡ndose en su historial.

```bash
uv run python -m src.inference \
  --mode recommend \
  --user_id "user_000238" \
  --data_path "data/spotify-kaggle/interim/lastfm_spotify_merged.csv" \
  --mapper_path "data/spotify-kaggle/interim/item_id_mapper.json" \
  --model_path "checkpoints/best_model.pth" \
  --encoders_path "checkpoints/encoders.pkl" \
  --index_path "checkpoints/item_index.pt"
```

-----

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ data/               # Datos crudos y procesados (gestionado por DVC)
â”œâ”€â”€ notebooks/          # Jupyter Notebooks para EDA y prototipado
â”œâ”€â”€ src/                # CÃ³digo fuente
â”‚   â”œâ”€â”€ dataset.py      # Clase MultimodalDataset y lÃ³gica de carga
â”‚   â”œâ”€â”€ models/         # DefiniciÃ³n de arquitecturas (TwoTower, Encoders)
â”‚   â”œâ”€â”€ train.py        # Script de entrenamiento
â”‚   â”œâ”€â”€ inference.py    # Script de inferencia y recomendaciÃ³n
â”‚   â””â”€â”€ evaluate_metrics.py # Script de evaluaciÃ³n
â”œâ”€â”€ checkpoints/        # Modelos entrenados y encoders guardados
â”œâ”€â”€ pyproject.toml      # Dependencias y configuraciÃ³n del proyecto
â””â”€â”€ uv.lock             # Lockfile de dependencias
```

-----

## ğŸ¤ Flujo de Trabajo Colaborativo



-----

## ğŸ‘¥ Equipo y Roles



## ğŸ“œ Licencia



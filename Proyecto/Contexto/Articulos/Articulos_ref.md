### 1. El est谩ndar de la industria (Arquitectura Two-Tower)

Estos art铆culos son obligatorios para justificar por qu茅 elegiste una arquitectura de dos torres. Son la base de los sistemas de recuperaci贸n (retrieval) en **YouTube** y  **Google** .

* **"Deep Neural Networks for YouTube Recommendations" (Covington et al., 2016)**
  * **Contexto:** Este es el *paper* fundacional que introdujo la idea de separar el problema en "Candidat Generation" (Retrieval) y "Ranking". Aunque usaron una arquitectura m谩s simple, establece el flujo de trabajo que t煤 sigues.
  * **Por qu茅 citarlo:** Para justificar la estructura general de tu sistema y la necesidad de lidiar con millones de 铆tems (escalabilidad).
* **"Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Retrieval" (Yi et al., Google, 2019)**
  * **Contexto:** Este es el art铆culo que formaliza la arquitectura **Two-Tower** moderna que est谩s usando. Introduce c贸mo entrenar eficazmente dos codificadores separados (usuario e 铆tem) y hacer el *dot product* para la similaridad.
  * **Por qu茅 citarlo:** Es la referencia t茅cnica directa de tu arquitectura global.

### 2. Modelos de Spotify y Audio (Validaci贸n de tu Item Tower)

Tu proyecto procesa audio crudo -> Espectrogramas Mel -> CNN (ResNet). **Spotify** fue pionero en esto.

* **"Deep content-based music recommendation" (Van den Oord, Dieleman, Schrauwen, 2013)**
  * **Contexto:** Sander Dieleman (quien luego trabaj贸 en Spotify y DeepMind) demostr贸 que usar CNNs sobre espectrogramas Mel pod铆a predecir factores latentes para recomendaci贸n. Es la base cient铆fica de tu m贸dulo de audio.
  * **Por qu茅 citarlo:** Valida tu decisi贸n de usar Mel-Spectrograms + CNNs (ResNet) en lugar de usar metadatos manuales. Es el argumento central para solucionar el *Cold-Start* en m煤sica.
* **"Recommending Long-tail Music" (Spotify Research)**
  * Aunque a veces no publican *papers* acad茅micos tradicionales, puedes citar trabajos como **"The Long Tail of Recommender Systems"** o referencias a su sistema "BaRT" (Bandits for Recommendations as Treatments) si quisieras hablar de exploraci贸n, pero para tu tesis, el de Dieleman (2013) es el m谩s cr铆tico.

### 3. Modelos Secuenciales (Validaci贸n de tu User Tower)

Est谩s usando **SASRec** en tu torre de usuario. Debes citar el origen de esto y su evoluci贸n (estilo BERT), que es lo que usan plataformas como **Alibaba** o **TikTok** (indirectamente, a trav茅s de modelos de atenci贸n secuencial).

* **"Self-Attentive Sequential Recommendation" (Kang & McAuley, 2018)**
  * **Contexto:** El paper original de  **SASRec** . Demuestra que usar mecanismos de auto-atenci贸n (Transformers) supera a las RNNs/LSTMs para modelar el historial del usuario.
  * **Por qu茅 citarlo:** Es la cita obligatoria para tu  *User Tower* .
* **"BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer" (Sun et al., 2019)**
  * **Contexto:** La evoluci贸n de SASRec usando BERT (bidireccional).
  * **Por qu茅 citarlo:** Sirve para dar contexto en el estado del arte ("State of the Art" o SOTA) en la introducci贸n, mostrando que los Transformers dominan el campo.

### 4. TikTok y Redes Neuronales Profundas (Interacci贸n compleja)

Para mencionar modelos tipo **TikTok** (ByteDance) o sistemas que modelan intereses evolutivos muy r谩pidos.

* **"Deep Interest Network for Click-Through Rate Prediction" (Zhou et al., Alibaba, 2018)**
  * **Contexto:** Aunque es de Alibaba, este modelo (DIN) y su sucesor (DIEN) introdujeron la idea de atender selectivamente a partes del historial del usuario relevantes para el 铆tem candidato actual. Es muy similar a la l贸gica de "scroll infinito" y recomendaci贸n inmediata de TikTok.
  * **Por qu茅 citarlo:** Para contrastar tu enfoque. Tu usas *embeddings* fijos por sesi贸n (Two-Tower), mientras que estos modelos hacen atenci贸n "target-user". Sirve para enriquecer la secci贸n de "Trabajos Relacionados".
* **"Monolith: Real Time Recommendation System With Collisionless Embedding Table" (Liu et al., ByteDance, 2022)**
  * **Contexto:** Un *paper* t茅cnico de ByteDance (due帽os de TikTok) sobre c贸mo manejan *embeddings* en tiempo real y colisiones de datos.
  * **Por qu茅 citarlo:** Si quieres mencionar expl铆citamente tecnolog铆a de **TikTok/ByteDance** en cuanto a ingenier铆a de *embeddings* y manejo de  *sparsity* .

### 5. Netflix (Autoencoders y Filtrado Colaborativo)

* **"Variational Autoencoders for Collaborative Filtering" (Liang et al., Netflix/MIT, 2018)**
  * **Contexto:** Introduce  **Mult-VAE** . Netflix usa una variedad de modelos, pero este paper fue muy influyente al mostrar que los Autoencoders Variacionales eran superiores para el filtrado colaborativo impl铆cito.
  * **Por qu茅 citarlo:** Como un ejemplo de arquitecturas profundas alternativas (no secuenciales) que se usan en la industria para "Matrix Factorization" no lineal.

### Resumen de c贸mo integrarlos en tu Introducci贸n:

Puedes estructurar un p谩rrafo as铆 (ejemplo):

> *"En la industria actual, la arquitectura predominante para la recuperaci贸n eficiente de 铆tems en cat谩logos masivos es el enfoque  **Two-Tower** , popularizado por **YouTube** [Covington et al., 2016] y perfeccionado por **Google** [Yi et al., 2019]. Para el modelado de preferencias de usuario, los enfoques secuenciales basados en auto-atenci贸n, como **SASRec** [Kang & McAuley, 2018], han demostrado superar a los m茅todos tradicionales, capturando la evoluci贸n din谩mica de intereses similar a lo observado en plataformas como **TikTok** o **Alibaba** [Zhou et al., 2018]. Sin embargo, en el dominio musical, el problema de arranque en fr铆o ('Cold-Start') persiste. Inspirados por los trabajos pioneros de **Spotify** en el uso de redes convolucionales sobre espectrogramas de audio [Van den Oord et al., 2013], nuestra propuesta integra..."*



### 1. El est谩ndar Two-Tower (YouTube/Google)

Estos son los documentos fundamentales para tu arquitectura global.

* **"Deep Neural Networks for YouTube Recommendations"** (Covington et al., 2016)
  *  **PDF:** [Google Research PDF](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)
  * Este es el cl谩sico que define la separaci贸n entre *Candidate Generation* y  *Ranking* .
* **"Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Retrieval"** (Yi et al., 2019)
  *  **PDF:** [Google Research PDF](https://research.google/pubs/pub48840/) (Busca el bot贸n "Download PDF" en la p谩gina) o v铆a [ACM Digital Library](https://dl.acm.org/doi/10.1145/3298689.3346996).
  * Este formaliza la correcci贸n de sesgo en el *softmax* que es crucial para entrenar Two-Towers correctamente.

### 2. Audio y M煤sica (Spotify)

La base para tu "Item Tower" de procesamiento de audio.

* **"Deep content-based music recommendation"** (Van den Oord, Dieleman, Schrauwen, 2013)
  *  **PDF:** [NIPS Proceedings](https://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf)
  * El paper original que demostr贸 el uso de CNNs sobre espectrogramas Mel para recomendaci贸n.

### 3. Modelos Secuenciales (User Tower)

Las referencias para tu implementaci贸n de SASRec.

* **"Self-Attentive Sequential Recommendation"** (SASRec - Kang & McAuley, 2018)
  *  **Link:** [arXiv:1808.09781](https://arxiv.org/abs/1808.09781)
  * El paper que introdujo el uso de Transformers para secuencias de usuario.
* **"BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer"** (Sun et al., 2019)
  *  **Link:** [arXiv:1904.06690](https://arxiv.org/abs/1904.06690)
  * La evoluci贸n bidireccional de SASRec.

### 4. Interacci贸n Compleja y Tiempo Real (Alibaba/TikTok/ByteDance)

Referencias adicionales para la discusi贸n del estado del arte.

* **"Deep Interest Network for Click-Through Rate Prediction"** (DIN - Zhou et al., Alibaba, 2018)
  *  **Link:** [arXiv:1706.06978](https://arxiv.org/abs/1706.06978)
  * Sobre c贸mo atender a partes espec铆ficas del historial del usuario (Atenci贸n local vs. Global).
* **"Monolith: Real Time Recommendation System With Collisionless Embedding Table"** (Liu et al., ByteDance, 2022)
  *  **Link:** [arXiv:2209.07663](https://arxiv.org/abs/2209.07663)
  * La arquitectura detr谩s de TikTok para manejo de embeddings en tiempo real.

### 5. Filtrado Colaborativo Profundo (Netflix)

Alternativa no secuencial.

* **"Variational Autoencoders for Collaborative Filtering"** (Mult-VAE - Liang et al., 2018)
  *  **Link:** [arXiv:1802.05814](https://arxiv.org/abs/1802.05814)
  * El uso de Autoencoders Variacionales para recomendaci贸n impl铆cita.
